# ğŸš— CAV Security Game Theory Simulations

**Interactive simulations for analyzing security decisions in Connected and Autonomous Vehicles (CAVs) using game-theoretic models.**

This project is a Streamlit-based application that models cybersecurity scenarios in automotive networks. It provides interactive visualizations and solvers for two specific game theory models: **Stackelberg Security Games** for IDS placement and **Bayesian Signaling Games** for GPS spoofing detection.

## ğŸŒŸ Key Features

### 1\. ğŸ›¡ï¸ IDS Placement Game (Stackelberg Game)

Models the interaction between a defender placing Intrusion Detection Systems (IDS) and an attacker targeting Electronic Control Units (ECUs).

  * **Game Type:** Leader-Follower (Stackelberg). The defender commits to a defense strategy, and the attacker observes and optimizes their attack.
  * **Simulation Features:**
      * **Network Topology:** Visualizes the vehicle network and protected nodes.
      * **Algorithms:** Compare three different placement strategies:
          * **Exact:** Exhaustive search (optimal for small N).
          * **Greedy Heuristic:** Fast, near-optimal placement based on criticality.
          * **Genetic Algorithm:** Evolutionary approach for complex spaces.
      * **Analysis:** Comparison of computation time, defender payoff, and attack targets.

### 2\. ğŸ“¡ GPS Spoofing Game (Bayesian Game)

Models a scenario where an attacker may inject spoofed GPS signals, and the defender must decide whether to verify the signal based on observed deviations.

  * **Game Type:** Bayesian Signaling Game with incomplete information. The defender uses Bayes' rule to update their belief about whether a signal is benign noise or a malicious attack.
  * **Simulation Features:**
      * **Belief Updates:** Visualizes how the probability of an attack changes based on signal deviation.
      * **Equilibrium Analysis:** Determines if the game state results in a Separating, Pooling, or Semi-Separating equilibrium.
      * **ROC Analysis:** Receiver Operating Characteristic curves for detection thresholds.
      * **Repeated Games:** Simulates the game over multiple rounds to track cumulative payoffs and detection rates.

## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ app.py                      # Main entry point for the Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ algorithms/                 # Game theory logic and solvers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ stackelberg.py          # Solvers for IDS placement (Exact, Greedy, Genetic)
â”‚   â”œâ”€â”€ bayesian.py             # Logic for belief updates and Bayesian equilibrium
â”‚   â””â”€â”€ utils.py                # Helper functions (payoffs, plotting, etc.)
â””â”€â”€ pages/                      # Streamlit multipage files
    â”œâ”€â”€ 1_IDS_Placement_Game.py # UI for the IDS Simulation
    â””â”€â”€ 2_GPS_Spoofing_Game.py  # UI for the GPS Spoofing Simulation
```

## ğŸš€ Installation & Usage

### Prerequisites

  * Python 3.8 or higher

### 1\. Clone the Repository

```bash
git clone <repository-url>
cd GameTheory-Simulations
```

### 2\. Create a Virtual Environment (Optional but Recommended)

```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3\. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4\. Run the Application

```bash
streamlit run app.py
```

The application will launch in your default web browser (typically at `http://localhost:8501`).

## ğŸ“š Theoretical Background

### Stackelberg Equilibrium

In the **IDS Placement Game**, the Defender acts as the *Leader*, committing to a randomized allocation of IDS resources. The Attacker acts as the *Follower*, observing the defense strategy and attacking the ECU that maximizes their utility. The solver finds the allocation that maximizes the Defender's utility assuming the Attacker plays optimally.

### Bayesian Belief Update

In the **GPS Spoofing Game**, the Defender observes a signal deviation $d$. They update their belief $\mu$ (probability the signal is malicious) using Bayes' Rule:

$$\mu(\text{Malicious} | d) = \frac{P(d | \text{Malicious}) \times P(\text{Malicious})}{P(d)}$$

The Defender verifies the signal only if the posterior belief exceeds a calculated threshold $\tau$.

## ğŸ› ï¸ Built With

  * **[Streamlit](https://streamlit.io/):** Interactive web interface.
  * **[Plotly](https://plotly.com/python/):** Interactive charts and network graphs.
  * **[NetworkX](https://networkx.org/):** Graph topology for ECU networks.
  * **[NumPy](https://numpy.org/) & [SciPy](https://scipy.org/):** Mathematical computations and statistical distributions.
